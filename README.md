# TransformersFromScratch
Code from Machine Learning Mastery

Attention:
https://machinelearningmastery.com/how-to-implement-scaled-dot-product-attention-from-scratch-in-tensorflow-and-keras/

Multihead attention
https://machinelearningmastery.com/how-to-implement-multi-head-attention-from-scratch-in-tensorflow-and-keras/

Encoder:
https://machinelearningmastery.com/implementing-the-transformer-encoder-from-scratch-in-tensorflow-and-keras/

Decoder:
https://machinelearningmastery.com/implementing-the-transformer-decoder-from-scratch-in-tensorflow-and-keras/

Joining the Encoder and the Decoder
https://machinelearningmastery.com/joining-the-transformer-encoder-and-decoder-and-masking/

Training the transformer
https://machinelearningmastery.com/training-the-transformer-model/
